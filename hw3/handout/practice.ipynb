{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr1 = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "arr2 = np.array([[3, 2], [7, 1], [4, 4]])\n",
    "# # arr1 = np.array([[1, 2]])\n",
    "# # arr2 = np.array([[3, 2]])\n",
    "# dist_sum = 0\n",
    "# for i in np.nditer(arr1):\n",
    "#     for j in np.nditer(arr2):\n",
    "#         dist_sum += (i - j) ** 2\n",
    "# euclidean_dist = np.sqrt(dist_sum)\n",
    "# euclidean_dist \n",
    "for i in arr1:\n",
    "    print(i[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "arr2 = [5, 6, 7, 8]\n",
    "dist_sum = 0\n",
    "for i in range(len(arr1)):\n",
    "        dist_sum += (arr1[i] - arr2[i]) ** 2\n",
    "\n",
    "euclidean_dist = np.sqrt(dist_sum)\n",
    "euclidean_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [2, 1, 5]\n",
    "labels = [label for label in arr1[indices]]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in ks:\n",
    "    #     # shuffle the data\n",
    "    #     np.random.shuffle(train_data)\n",
    "    #     # split the data into folds\n",
    "    #     folds = []\n",
    "    #     for i in range(num_folds):\n",
    "    #         start_idx = fold_size * i\n",
    "    #         end_idx = fold_size * (i + 1)\n",
    "    #         fold = train_data[start_idx:end_idx]\n",
    "    #         folds.append(fold)\n",
    "    #     # split training and test data in each fold\n",
    "    #     errs_sum = 0\n",
    "    #     preds_ls = []\n",
    "    #     for idx in range(len(folds)):\n",
    "    #         test_fold = folds[idx]\n",
    "    #         test_fold_fetures = test_fold[:, :-1]\n",
    "    #         test_fold_labels = test_fold[:, -1]\n",
    "    #         train_folds = folds[np.arange(len(folds)) != idx]\n",
    "    #         # predict and compute error rate for different training and test folds\n",
    "    #         preds = predict(k, dist_metric, train_folds, test_fold_fetures)\n",
    "    #         preds_ls.append(preds)\n",
    "    #         err_rate = compute_error(preds, test_fold_labels)\n",
    "    #         errs_sum += err_rate\n",
    "    #     err_rate = errs_sum / len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv('iris_train.csv').to_numpy()\n",
    "train_features = train_data[:, :-1]\n",
    "train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 10\n",
    "folds = []\n",
    "fold_size = len(train_data) // num_folds\n",
    "for i in range(num_folds):\n",
    "    start_idx = fold_size * i\n",
    "    end_idx = fold_size * (i + 1)\n",
    "    fold = train_data[start_idx:end_idx]\n",
    "    folds.append(fold)\n",
    "\n",
    "# handle the case where the number of folds does not divide evenly into the number of data points\n",
    "remainder = len(train_data) % num_folds\n",
    "if remainder != 0:\n",
    "    for i in range(remainder):\n",
    "        folds[i] = np.append(folds[i], train_data[-(i+1)]) # assign the remaining data to the folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fold = folds[2]\n",
    "test_fold_features = test_fold[:, :-1]\n",
    "# test_fold_features\n",
    "train_folds = folds[:2] + folds[3:]\n",
    "train_folds_arr = np.concatenate(train_folds)\n",
    "type(train_folds_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict and compute error rate \n",
    "from knn import predict, compute_error\n",
    "err_sum = 0\n",
    "test_fold_labels = test_fold[:, -1]\n",
    "preds = predict(5, 0, train_folds_arr, test_fold_features)\n",
    "preds_arr = np.array(preds)\n",
    "err_rate = compute_error(preds_arr, test_fold_labels)\n",
    "err_sum += err_rate\n",
    "preds_arr\n",
    "# preds_ls.append(preds)\n",
    "# preds_arr = np.array(preds_ls)\n",
    "# err_rate = compute_error(preds_arr, test_fold_labels)\n",
    "# errs_sum += err_rate\n",
    "# err_rate = errs_sum / len(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = range(1, 5)\n",
    "for k in ks:\n",
    "    errs_sum = 0\n",
    "    preds_ls = []\n",
    "    for idx in range(len(folds)): # create different training and test folds\n",
    "        test_fold = folds[idx]\n",
    "        test_fold_fetures = test_fold[:, :-1]\n",
    "        test_fold_labels = test_fold[:, -1]\n",
    "        train_folds = folds[:idx] + folds[idx+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn import euclidean_dist\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "train_labels = train_data[:, -1]\n",
    "pred_labels = []\n",
    "X = pd.read_csv('iris_val.csv').to_numpy()[:, :-1]\n",
    "\n",
    "# get each data point(row) in X and each data point in train data and compute distance\n",
    "for data_point in X:\n",
    "    dist_ls = []\n",
    "    for data_point_train in train_features:\n",
    "        # if dist_metric == 0:\n",
    "        dist = euclidean_dist(data_point, data_point_train)\n",
    "        # if dist_metric == 1:\n",
    "        #     dist = manhattan_dist(data_point, data_point_train)\n",
    "        dist_ls.append(dist)\n",
    "    # get top 5 neighbors  \n",
    "    k_tuples = sorted(enumerate(dist_ls), key=lambda x:x[1])[:5]\n",
    "    k_indices = [index for index, value in k_tuples]\n",
    "    labels = [train_labels[idx] for idx in k_indices]\n",
    "    # majority vote to finalize label\n",
    "    counter = Counter(labels)\n",
    "    # major_vote = counter.most_common(1)\n",
    "    # if len(major_vote) > 1:\n",
    "    #     for vote in major_vote:\n",
    "    #         vote[0]\n",
    "    #     label_indices = counter\n",
    "    pred_label = counter.most_common(1)[0][0]\n",
    "    pred_labels.append(pred_label)\n",
    "\n",
    "pred_arr = np.array(pred_labels)\n",
    "pred_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = pd.read_csv('iris_val.csv').to_numpy()[:, -1]\n",
    "error = 0\n",
    "for i in range(len(pred_arr)):\n",
    "    if pred_arr[i] != val_labels[i]:\n",
    "            error += 1\n",
    "error_rate = error / len(labels)\n",
    "error_rate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from knn import crossval_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "val_data = pd.read_csv('iris_val.csv').to_numpy()\n",
    "train_val_data = np.concatenate((train_data, val_data), axis = 0)\n",
    "k_range = range(1, 4)\n",
    "num_folds = 10\n",
    "# shuffle the data\n",
    "np.random.shuffle(train_val_data)\n",
    "# split the data into folds\n",
    "folds = []\n",
    "fold_size = len(train_val_data) // num_folds\n",
    "for i in range(num_folds):\n",
    "    start_idx = fold_size * i\n",
    "    end_idx = fold_size * (i + 1)\n",
    "    fold = train_val_data[start_idx:end_idx]\n",
    "    folds.append(fold)\n",
    "# handle the case where the number of folds does not divide evenly into the number of data points\n",
    "remainder = len(train_val_data) % num_folds\n",
    "if remainder != 0:\n",
    "    for i in range(remainder):\n",
    "        folds[i] = np.append(folds[i], train_data[-(i+1)]) # assign the remaining data to the folds\n",
    "# folds is now a list of 2d arrays\n",
    "\n",
    "# split training and test data in each fold\n",
    "for k in k_range:\n",
    "    errs_sum = 0\n",
    "    preds_ls = []\n",
    "    for idx in range(len(folds)): # create different combination of train and test folds\n",
    "        test_fold = folds[idx]\n",
    "        test_fold_features = test_fold[:, :-1]\n",
    "        test_fold_labels = test_fold[:, -1]\n",
    "        train_folds = folds[:idx] + folds[idx+1:]\n",
    "        train_folds_arr = np.concatenate(train_folds) # transform train_folds from list to a big array\n",
    "        # predict and compute error rate \n",
    "        preds = predict(k, 0, train_folds_arr, test_fold_features)\n",
    "        preds_arr = np.array(preds)\n",
    "        error = compute_error(preds_arr, test_fold_labels)\n",
    "        errs_sum += error\n",
    "    err_rate = errs_sum / len(folds)\n",
    "    print(k, err_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = crossval_model(k_range, 10, 0, train_val_data)\n",
    "res\n",
    "\n",
    "# prdict\n",
    "# corssval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
